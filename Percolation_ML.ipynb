{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as cp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def grid(n, prob):\n",
    "    \"\"\"\n",
    "    Construct a grid with dimension n with probability prob\n",
    "    \"\"\"\n",
    "    return np.random.choice([0, 1], size=(n, n), p=[prob, 1-prob])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_data(samples, n, prob):\n",
    "    \"\"\"\n",
    "    samples: number of samples (int)\n",
    "    n: size of matrix  (odd int)\n",
    "    prob: probability of getting 1 or 0 (0<=prob<=1)\n",
    "    \"\"\"\n",
    "    count = 0.\n",
    "    mat = []\n",
    "    vd = np.zeros(samples)\n",
    "    for ind in range(samples):\n",
    "        b = grid(n, prob)\n",
    "        mat.append(cp.copy(b)) #Used copy to not have 2 on the matrix\n",
    "        b[(n-1)//2][(n-1)//2] = 2\n",
    "        stop = False\n",
    "        while not stop:\n",
    "            change = False\n",
    "            for i, j in zip(*np.where(b == 2)):\n",
    "                if i == 0 or j == 0 or i == n - 1 or j == n - 1:\n",
    "                    count += 1\n",
    "                    stop = True\n",
    "                    vd[ind] = 1\n",
    "                    break\n",
    "                if b[i+1, j] == 0:\n",
    "                    b[i+1, j] = 2\n",
    "                    change = True\n",
    "                if b[i, j+1] == 0:\n",
    "                    b[i, j+1] = 2\n",
    "                    change = True\n",
    "                if b[i-1, j] == 0:\n",
    "                    b[i-1, j] = 2\n",
    "                    change = True\n",
    "                if b[i, j-1] == 0:\n",
    "                    b[i, j-1] = 2\n",
    "                    change = True\n",
    "            if not change:\n",
    "                stop = True\n",
    "    return np.array(mat),vd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nahum/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(11, 11)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation= tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning data\n",
    "td,tr = writing_data(1000,11,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show sample of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "        [1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
       "        [1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]]), 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td[0], tr[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1000/1000 [==============================] - 0s 239us/sample - loss: 0.6640 - acc: 0.6350\n",
      "Epoch 2/12\n",
      "1000/1000 [==============================] - 0s 82us/sample - loss: 0.5820 - acc: 0.6930\n",
      "Epoch 3/12\n",
      "1000/1000 [==============================] - 0s 98us/sample - loss: 0.5201 - acc: 0.7650\n",
      "Epoch 4/12\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 0.4384 - acc: 0.8150\n",
      "Epoch 5/12\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 0.3605 - acc: 0.8700\n",
      "Epoch 6/12\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 0.2996 - acc: 0.8950\n",
      "Epoch 7/12\n",
      "1000/1000 [==============================] - 0s 93us/sample - loss: 0.2444 - acc: 0.9220\n",
      "Epoch 8/12\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 0.1687 - acc: 0.9540\n",
      "Epoch 9/12\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 0.1081 - acc: 0.9830\n",
      "Epoch 10/12\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 0.0810 - acc: 0.9890\n",
      "Epoch 11/12\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.0495 - acc: 0.9990\n",
      "Epoch 12/12\n",
      "1000/1000 [==============================] - 0s 122us/sample - loss: 0.0242 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa32d144f50>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(td,tr, epochs = 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 91us/sample - loss: 0.3904 - acc: 0.8680\n",
      "('Test accuracy:', 0.868)\n"
     ]
    }
   ],
   "source": [
    "test_mat,test_v = writing_data(1000,11,0.6)\n",
    "test_loss, test_acc = model.evaluate(test_mat, test_v)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting the probability versus the accuracy of the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a plot that shows that the accuracy decreases on the critical probability for the model.\n",
    "\n",
    "The way to acquire data for the plot is given in the line below the plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(probability,acc, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 49us/sample - loss: 1.1921e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 1.2529e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 1.3614e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - ETA: 0s - loss: 1.7509e-07 - acc: 1.000 - 0s 41us/sample - loss: 1.4579e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 1.6057e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 1.7953e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 1.8537e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 2.2161e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 2.3103e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 69us/sample - loss: 2.7716e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 3.0231e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 3.6430e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 4.0436e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 3.7146e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 4.5085e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 4.6349e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 7.1537e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 6.3359e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 7.3683e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 9.7607e-07 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 1.2342e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 1.0663e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 1.2932e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 62us/sample - loss: 2.1076e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.7825e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 2.3600e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 2.0948e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 4.0086e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 2.0988e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 6.3614e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 9.1165e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 6.1066e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 6.0753e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 1.3779e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 8.3673e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 6.1159e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 7.5107e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 9.5857e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 1.1487e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 1.3862e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 1.0966e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 1.3213e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 2.9124e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 101us/sample - loss: 5.6694e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 1.6091e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 2.5054e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 1.6049e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 3.7822e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 4.7332e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 95us/sample - loss: 2.3799e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 3.1037e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 84us/sample - loss: 9.4447e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 2.8369e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 6.2715e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 1.1293e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 9.8370e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 1.0938e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 2.4922e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 1.7614e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 2.9190e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 67us/sample - loss: 4.9619e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 2.9525e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 3.2511e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0047 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0013 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 3.5945e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 7.8610e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0093 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0029 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0032 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 70us/sample - loss: 0.0097 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 8.3419e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0119 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0033 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0146 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0015 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0141 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0017 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0108 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0095 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0135 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0091 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0053 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0249 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0226 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0254 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0367 - acc: 0.9920\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0400 - acc: 0.9940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0528 - acc: 0.9880\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0184 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0290 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0470 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0186 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0400 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0197 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0433 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0402 - acc: 0.9920\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0433 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0499 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0268 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0701 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0360 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0665 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0509 - acc: 0.9880\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0718 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0801 - acc: 0.9820\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0894 - acc: 0.9750\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0663 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0914 - acc: 0.9730\n",
      "1000/1000 [==============================] - 0s 83us/sample - loss: 0.0634 - acc: 0.9790\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 0.1077 - acc: 0.9760\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0830 - acc: 0.9770\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1039 - acc: 0.9730\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.1050 - acc: 0.9680\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1077 - acc: 0.9670\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1202 - acc: 0.9670\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1150 - acc: 0.9720\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1107 - acc: 0.9640\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0931 - acc: 0.9750\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.1337 - acc: 0.9590\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.1402 - acc: 0.9570\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1603 - acc: 0.9560\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1795 - acc: 0.9450\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1471 - acc: 0.9520\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.1322 - acc: 0.9660\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.1817 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.1856 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2223 - acc: 0.9310\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1803 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.2143 - acc: 0.9410\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.1996 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.2161 - acc: 0.9360\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2157 - acc: 0.9270\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.2443 - acc: 0.9200\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2586 - acc: 0.9300\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2907 - acc: 0.9200\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2347 - acc: 0.9220\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.2998 - acc: 0.9050\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2836 - acc: 0.9050\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2823 - acc: 0.9080\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.3175 - acc: 0.9060\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.2847 - acc: 0.9130\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2679 - acc: 0.9000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.2613 - acc: 0.9130\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3672 - acc: 0.8880\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.3075 - acc: 0.8990\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2952 - acc: 0.9080\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.3813 - acc: 0.8860\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.3672 - acc: 0.8840\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.4061 - acc: 0.8740\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3757 - acc: 0.8790\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.3877 - acc: 0.8600\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.4248 - acc: 0.8660\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.4075 - acc: 0.8580\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.4300 - acc: 0.8600\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.4616 - acc: 0.8580\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.4049 - acc: 0.8510\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.4367 - acc: 0.8460\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.4616 - acc: 0.8320\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.5087 - acc: 0.8330\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.4794 - acc: 0.8340\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.5627 - acc: 0.8220\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.5079 - acc: 0.8330\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.5395 - acc: 0.8220\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.5083 - acc: 0.8220\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.5749 - acc: 0.8000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.6146 - acc: 0.7900\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.6588 - acc: 0.7960\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.6468 - acc: 0.7840\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.6436 - acc: 0.7860\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.6026 - acc: 0.7800\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.6493 - acc: 0.7850\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.7427 - acc: 0.7580\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.7127 - acc: 0.7760\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.6961 - acc: 0.7600\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.7567 - acc: 0.7560\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.7595 - acc: 0.7510\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.7857 - acc: 0.7370\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.7626 - acc: 0.7550\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8354 - acc: 0.7190\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.8485 - acc: 0.7360\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8214 - acc: 0.7190\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.8126 - acc: 0.7300\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.8565 - acc: 0.7150\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.8491 - acc: 0.7320\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.8820 - acc: 0.7320\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.9123 - acc: 0.7130\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.9688 - acc: 0.6830\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.9194 - acc: 0.6950\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.8535 - acc: 0.7180\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 1.0035 - acc: 0.6750\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.9277 - acc: 0.6950\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8775 - acc: 0.7000\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.8591 - acc: 0.7070\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.8558 - acc: 0.7240\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9137 - acc: 0.6890\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9849 - acc: 0.6600\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8518 - acc: 0.6980\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.9704 - acc: 0.6780\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 1.0489 - acc: 0.6530\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9679 - acc: 0.6650\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 1.0056 - acc: 0.6730\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9849 - acc: 0.6790\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 1.0289 - acc: 0.6680\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9976 - acc: 0.6820\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9591 - acc: 0.6660\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 1.1692 - acc: 0.6370\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 1.0776 - acc: 0.6610\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 1.0943 - acc: 0.6260\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 1.1337 - acc: 0.6420\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 1.0906 - acc: 0.6330\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.1105 - acc: 0.6330\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 1.1173 - acc: 0.6420\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.1003 - acc: 0.6490\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.9844 - acc: 0.6560\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 1.0090 - acc: 0.6540\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.9959 - acc: 0.6640\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.2096 - acc: 0.6100\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.0673 - acc: 0.6460\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.9890 - acc: 0.6590\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 1.1324 - acc: 0.6490\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.1500 - acc: 0.6310\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 1.0360 - acc: 0.6380\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 1.1031 - acc: 0.6340\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 1.1123 - acc: 0.6370\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 1.1828 - acc: 0.6070\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.0888 - acc: 0.6310\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 1.0694 - acc: 0.6640\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.0778 - acc: 0.6550\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 1.0490 - acc: 0.6500\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 1.0555 - acc: 0.6310\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 1.0011 - acc: 0.6640\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 1.0933 - acc: 0.6360\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 1.0563 - acc: 0.6470\n",
      "1000/1000 [==============================] - 0s 29us/sample - loss: 1.0716 - acc: 0.6500\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.9962 - acc: 0.6510\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 1.0436 - acc: 0.6510\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.1056 - acc: 0.6340\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 1.0490 - acc: 0.6740\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.9382 - acc: 0.6800\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 1.0356 - acc: 0.6690\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 1.0027 - acc: 0.6680\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 1.0171 - acc: 0.6650\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.9854 - acc: 0.6650\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.9933 - acc: 0.6790\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 1.0059 - acc: 0.6850\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 1.0030 - acc: 0.6790\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.8959 - acc: 0.6990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.9624 - acc: 0.6860\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9509 - acc: 0.7130\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.9460 - acc: 0.6860\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.8984 - acc: 0.6940\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8931 - acc: 0.7120\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 1.0349 - acc: 0.6780\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8452 - acc: 0.7080\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.7773 - acc: 0.7440\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9714 - acc: 0.7000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8714 - acc: 0.7250\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.8893 - acc: 0.7130\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.9386 - acc: 0.7000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8744 - acc: 0.7080\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8732 - acc: 0.7390\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.7395 - acc: 0.7660\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.7943 - acc: 0.7420\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.7349 - acc: 0.7370\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.7999 - acc: 0.7390\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.7527 - acc: 0.7440\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8174 - acc: 0.7510\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8392 - acc: 0.7220\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.8310 - acc: 0.7400\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.7892 - acc: 0.7470\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.8031 - acc: 0.7440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.7291 - acc: 0.7610\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.6824 - acc: 0.7730\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5992 - acc: 0.7810\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.7309 - acc: 0.7740\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.6169 - acc: 0.7930\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.6787 - acc: 0.7740\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.6647 - acc: 0.7880\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.6119 - acc: 0.7920\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.6348 - acc: 0.7830\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.6163 - acc: 0.7980\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.6451 - acc: 0.7900\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.5768 - acc: 0.8060\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.5369 - acc: 0.8070\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5448 - acc: 0.8280\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.5569 - acc: 0.8270\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.5447 - acc: 0.8280\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.5773 - acc: 0.8290\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.5012 - acc: 0.8350\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.5871 - acc: 0.8210\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.4667 - acc: 0.8490\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.5147 - acc: 0.8410\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.4288 - acc: 0.8460\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.4542 - acc: 0.8620\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.4331 - acc: 0.8670\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.4673 - acc: 0.8440\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.4596 - acc: 0.8470\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.4112 - acc: 0.8720\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.4470 - acc: 0.8660\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3827 - acc: 0.8670\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.4066 - acc: 0.8640\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.4001 - acc: 0.8630\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.4506 - acc: 0.8510\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.3103 - acc: 0.8920\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 0.3701 - acc: 0.8770\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.4347 - acc: 0.8560\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.3424 - acc: 0.8920\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.3787 - acc: 0.8680\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3487 - acc: 0.8800\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.2930 - acc: 0.8950\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.2576 - acc: 0.9060\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.3547 - acc: 0.8870\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.2834 - acc: 0.8960\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3012 - acc: 0.9030\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.2867 - acc: 0.8890\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2673 - acc: 0.8920\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3091 - acc: 0.8920\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.2662 - acc: 0.9070\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.2735 - acc: 0.9080\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2294 - acc: 0.9180\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.2117 - acc: 0.9260\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1851 - acc: 0.9380\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.1730 - acc: 0.9360\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1972 - acc: 0.9270\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 0.2177 - acc: 0.9210\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.2217 - acc: 0.9180\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.2176 - acc: 0.9320\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.2109 - acc: 0.9230\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.2212 - acc: 0.9200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2142 - acc: 0.9360\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.2290 - acc: 0.9170\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.2104 - acc: 0.9320\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1876 - acc: 0.9290\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.1874 - acc: 0.9300\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.1442 - acc: 0.9510\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1604 - acc: 0.9420\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1533 - acc: 0.9410\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1734 - acc: 0.9460\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.1634 - acc: 0.9320\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1645 - acc: 0.9400\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.1319 - acc: 0.9530\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.1742 - acc: 0.9410\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.1684 - acc: 0.9320\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1370 - acc: 0.9570\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.1445 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.1201 - acc: 0.9500\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.1046 - acc: 0.9580\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.1268 - acc: 0.9550\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.1380 - acc: 0.9520\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1614 - acc: 0.9490\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1149 - acc: 0.9570\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1232 - acc: 0.9540\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.1142 - acc: 0.9550\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0905 - acc: 0.9650\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0991 - acc: 0.9600\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1067 - acc: 0.9640\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0814 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0718 - acc: 0.9710\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0744 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0855 - acc: 0.9720\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0857 - acc: 0.9660\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0940 - acc: 0.9650\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.1040 - acc: 0.9650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.1033 - acc: 0.9570\n",
      "1000/1000 [==============================] - 0s 61us/sample - loss: 0.0655 - acc: 0.9760\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0696 - acc: 0.9750\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0860 - acc: 0.9720\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0697 - acc: 0.9720\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0674 - acc: 0.9770\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0654 - acc: 0.9730\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0575 - acc: 0.9760\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.0704 - acc: 0.9720\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0525 - acc: 0.9760\n",
      "1000/1000 [==============================] - 0s 32us/sample - loss: 0.0506 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0486 - acc: 0.9820\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0630 - acc: 0.9720\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0805 - acc: 0.9760\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0543 - acc: 0.9800\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0522 - acc: 0.9770\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0456 - acc: 0.9830\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0417 - acc: 0.9850\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0436 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0464 - acc: 0.9850\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0490 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0486 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0535 - acc: 0.9800\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0326 - acc: 0.9920\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 0.0422 - acc: 0.9830\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0379 - acc: 0.9880\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0433 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0437 - acc: 0.9830\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0352 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0513 - acc: 0.9820\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0341 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0360 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0409 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0322 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0299 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0446 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0341 - acc: 0.9870\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0307 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0282 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0324 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0271 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0290 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0246 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0313 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0214 - acc: 0.9920\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0342 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0169 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 0.0237 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0290 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0207 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0232 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0196 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0183 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0278 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0230 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0157 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0224 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0154 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0183 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0182 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0234 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0179 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0221 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0202 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0249 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0237 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0173 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0163 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0190 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0119 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0159 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0173 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0129 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0118 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0133 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0104 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0154 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0128 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0092 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0115 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0124 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0124 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0125 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0127 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0118 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0112 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0101 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0134 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0143 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.0128 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0109 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.0123 - acc: 0.9970\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0132 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0125 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0091 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0135 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0137 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0127 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0089 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0100 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0114 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0096 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0117 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0091 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0126 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0116 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0118 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0131 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0095 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0128 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0144 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0120 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0136 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0139 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0127 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0138 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0135 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0151 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0179 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0184 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0171 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.0184 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0202 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0194 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 51us/sample - loss: 0.0219 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0287 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0288 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0299 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0333 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0383 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0419 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0497 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0573 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0669 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 0.0763 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 59us/sample - loss: 0.0905 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "probability = np.linspace(0.,1.,500)\n",
    "acc = np.zeros(len(probability))\n",
    "for i,v in enumerate(probability):\n",
    "    #test data\n",
    "    test_mat,test_v = writing_data(1000,11,v)\n",
    "    #evaluate accuracy\n",
    "    test_loss, test_acc = model.evaluate(test_mat, test_v)\n",
    "    acc[i] = test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
