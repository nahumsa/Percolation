{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy as cp\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "def grid(n, prob):\n",
    "    \"\"\"\n",
    "    Construct a grid with dimension n with probability prob\n",
    "    \"\"\"\n",
    "    return np.random.choice([0, 1], size=(n, n), p=[prob, 1-prob])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def writing_data(samples, n, prob):\n",
    "    \"\"\"\n",
    "    samples: number of samples (int)\n",
    "    n: size of matrix  (odd int)\n",
    "    prob: probability of getting 1 or 0 (0<=prob<=1)\n",
    "    \"\"\"\n",
    "    count = 0.\n",
    "    mat = []\n",
    "    vd = np.zeros(samples)\n",
    "    for ind in range(samples):\n",
    "        b = grid(n, prob)\n",
    "        mat.append(cp.copy(b)) #Used copy to not have 2 on the matrix\n",
    "        b[(n-1)//2][(n-1)//2] = 2\n",
    "        stop = False\n",
    "        while not stop:\n",
    "            change = False\n",
    "            for i, j in zip(*np.where(b == 2)):\n",
    "                if i == 0 or j == 0 or i == n - 1 or j == n - 1:\n",
    "                    count += 1\n",
    "                    stop = True\n",
    "                    vd[ind] = 1\n",
    "                    break\n",
    "                if b[i+1, j] == 0:\n",
    "                    b[i+1, j] = 2\n",
    "                    change = True\n",
    "                if b[i, j+1] == 0:\n",
    "                    b[i, j+1] = 2\n",
    "                    change = True\n",
    "                if b[i-1, j] == 0:\n",
    "                    b[i-1, j] = 2\n",
    "                    change = True\n",
    "                if b[i, j-1] == 0:\n",
    "                    b[i, j-1] = 2\n",
    "                    change = True\n",
    "            if not change:\n",
    "                stop = True\n",
    "    return np.array(mat),vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/nahum/anaconda2/lib/python2.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(11, 11)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(128, activation= tf.nn.relu),\n",
    "    keras.layers.Dense(2, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traning data\n",
    "td,tr = writing_data(1000,11,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1],\n",
       "        [1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1],\n",
       "        [1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1],\n",
       "        [0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0],\n",
       "        [0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1],\n",
       "        [0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1],\n",
       "        [1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1],\n",
       "        [0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0]]), 1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sample of training data\n",
    "td[0], tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "1000/1000 [==============================] - 0s 334us/sample - loss: 0.6680 - acc: 0.6220\n",
      "Epoch 2/12\n",
      "1000/1000 [==============================] - 0s 100us/sample - loss: 0.5765 - acc: 0.6980\n",
      "Epoch 3/12\n",
      "1000/1000 [==============================] - 0s 89us/sample - loss: 0.5197 - acc: 0.7430\n",
      "Epoch 4/12\n",
      "1000/1000 [==============================] - 0s 88us/sample - loss: 0.4641 - acc: 0.8010\n",
      "Epoch 5/12\n",
      "1000/1000 [==============================] - 0s 86us/sample - loss: 0.4075 - acc: 0.8380\n",
      "Epoch 6/12\n",
      "1000/1000 [==============================] - 0s 79us/sample - loss: 0.3486 - acc: 0.8580\n",
      "Epoch 7/12\n",
      "1000/1000 [==============================] - 0s 78us/sample - loss: 0.3082 - acc: 0.8820\n",
      "Epoch 8/12\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 0.2403 - acc: 0.9190\n",
      "Epoch 9/12\n",
      "1000/1000 [==============================] - 0s 81us/sample - loss: 0.1857 - acc: 0.9470\n",
      "Epoch 10/12\n",
      "1000/1000 [==============================] - 0s 92us/sample - loss: 0.1321 - acc: 0.9720\n",
      "Epoch 11/12\n",
      "1000/1000 [==============================] - 0s 96us/sample - loss: 0.0861 - acc: 0.9870\n",
      "Epoch 12/12\n",
      "1000/1000 [==============================] - 0s 105us/sample - loss: 0.0571 - acc: 0.9990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fd2357035d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training model\n",
    "model.fit(td,tr, epochs = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.4262 - acc: 0.8380\n",
      "('Test accuracy:', 0.838)\n"
     ]
    }
   ],
   "source": [
    "#test data\n",
    "test_mat,test_v = writing_data(1000,11,0.6)\n",
    "#evaluate accuracy\n",
    "test_loss, test_acc = model.evaluate(test_mat, test_v)\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.1921e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 1.2667e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.3589e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 1.4422e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 1.5756e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 1.6792e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 1.7003e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 1.9257e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 1.9662e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 2.2474e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 2.6902e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 2.8481e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 3.2804e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 3.4345e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 5.3845e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 4.6843e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 4.3537e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 5.5701e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 4.4096e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 5.7111e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 7.1823e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 6.5224e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 7.4894e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 7.7885e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 8.4391e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 9.1980e-06 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 1.0430e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 1.5693e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 1.4509e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 2.6668e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 2.2543e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 1.8579e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 2.5606e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 3.9027e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 2.5247e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 3.9888e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 74us/sample - loss: 3.3247e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 52us/sample - loss: 4.4347e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 3.5656e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 5.0980e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 4.0000e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 4.9113e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 4.8095e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 5.2454e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 7.9824e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 1.3570e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 2.2247e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 9.8436e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 1.3586e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 9.7812e-05 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0081 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 1.9633e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 2.0489e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 2.6622e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 2.1945e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 2.5714e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 3.6509e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 2.4566e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0103 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 4.4440e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0013 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 8.9228e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0170 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 3.7277e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0026 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 6.5710e-04 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.0097 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0011 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0086 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0012 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0016 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0022 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0117 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0013 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0058 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0018 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0038 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0017 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0110 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0152 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0168 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0094 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0130 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0172 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0271 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0035 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0151 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0055 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0058 - acc: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0268 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0184 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 0.0243 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0208 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 50us/sample - loss: 0.0329 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0206 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.0373 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0476 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 56us/sample - loss: 0.0360 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0498 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0569 - acc: 0.9880\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0471 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0247 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0375 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0831 - acc: 0.9790\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0590 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0562 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0530 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0456 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0960 - acc: 0.9740\n",
      "1000/1000 [==============================] - 0s 31us/sample - loss: 0.0797 - acc: 0.9740\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0490 - acc: 0.9830\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0930 - acc: 0.9740\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1005 - acc: 0.9730\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0789 - acc: 0.9810\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.1072 - acc: 0.9710\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0674 - acc: 0.9810\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0949 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1090 - acc: 0.9680\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1262 - acc: 0.9670\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1497 - acc: 0.9560\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.1174 - acc: 0.9640\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0870 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1145 - acc: 0.9700\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0954 - acc: 0.9650\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1232 - acc: 0.9610\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1792 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1666 - acc: 0.9510\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1265 - acc: 0.9580\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1365 - acc: 0.9540\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1481 - acc: 0.9560\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1982 - acc: 0.9460\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1573 - acc: 0.9510\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1760 - acc: 0.9400\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.2106 - acc: 0.9350\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1950 - acc: 0.9400\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.1944 - acc: 0.9440\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2421 - acc: 0.9240\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.2086 - acc: 0.9290\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.2324 - acc: 0.9240\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2325 - acc: 0.9340\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.2508 - acc: 0.9280\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2438 - acc: 0.9090\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.2460 - acc: 0.9160\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.2527 - acc: 0.9200\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2903 - acc: 0.9150\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.2995 - acc: 0.9070\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.2746 - acc: 0.9090\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3056 - acc: 0.8990\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.3150 - acc: 0.9030\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.3016 - acc: 0.8960\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3058 - acc: 0.9050\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3870 - acc: 0.8750\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.3783 - acc: 0.8710\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.4418 - acc: 0.8620\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.3856 - acc: 0.8780\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.3929 - acc: 0.8600\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.4229 - acc: 0.8530\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.5027 - acc: 0.8560\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.4161 - acc: 0.8410\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.4307 - acc: 0.8460\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3965 - acc: 0.8550\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.4411 - acc: 0.8400\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5030 - acc: 0.8330\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.4090 - acc: 0.8460\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.4907 - acc: 0.8310\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.5289 - acc: 0.8210\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.4795 - acc: 0.8250\n",
      "1000/1000 [==============================] - 0s 57us/sample - loss: 0.5597 - acc: 0.7960\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5211 - acc: 0.8010\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5944 - acc: 0.7970\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.5827 - acc: 0.7780\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.5888 - acc: 0.7890\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.5256 - acc: 0.8090\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.5513 - acc: 0.7980\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.6435 - acc: 0.7890\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.5976 - acc: 0.7940\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5751 - acc: 0.7900\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.6605 - acc: 0.7600\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.7017 - acc: 0.7640\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.7055 - acc: 0.7610\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.6835 - acc: 0.7460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.6268 - acc: 0.7500\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.6134 - acc: 0.7670\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.6766 - acc: 0.7400\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.7180 - acc: 0.7470\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.7345 - acc: 0.7280\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.6999 - acc: 0.7400\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.7896 - acc: 0.7380\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.7796 - acc: 0.7280\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.7278 - acc: 0.7400\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.8102 - acc: 0.7030\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.7531 - acc: 0.7150\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8590 - acc: 0.6850\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8255 - acc: 0.7060\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.8438 - acc: 0.6870\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.8398 - acc: 0.6970\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8127 - acc: 0.6950\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.7804 - acc: 0.7060\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9559 - acc: 0.6740\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8136 - acc: 0.6930\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.9389 - acc: 0.6690\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8646 - acc: 0.6860\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8844 - acc: 0.6520\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.8681 - acc: 0.6720\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9357 - acc: 0.6670\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.9291 - acc: 0.6470\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8193 - acc: 0.6990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.9102 - acc: 0.6550\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.9786 - acc: 0.6500\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9849 - acc: 0.6360\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.8768 - acc: 0.6690\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9804 - acc: 0.6620\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9080 - acc: 0.6600\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.8847 - acc: 0.6730\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.9558 - acc: 0.6520\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.9775 - acc: 0.6340\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.9947 - acc: 0.6390\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9663 - acc: 0.6470\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.9609 - acc: 0.6270\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 1.0151 - acc: 0.6400\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 1.0059 - acc: 0.6180\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 1.0166 - acc: 0.6340\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.9545 - acc: 0.6200\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.9625 - acc: 0.6440\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.9777 - acc: 0.6400\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.9033 - acc: 0.6540\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9722 - acc: 0.6480\n",
      "1000/1000 [==============================] - 0s 33us/sample - loss: 0.9032 - acc: 0.6560\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.9275 - acc: 0.6430\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9395 - acc: 0.6350\n",
      "1000/1000 [==============================] - 0s 48us/sample - loss: 0.9852 - acc: 0.6200\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.9318 - acc: 0.6500\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.9548 - acc: 0.6450\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.9577 - acc: 0.6470\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.9493 - acc: 0.6540\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8961 - acc: 0.6680\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9565 - acc: 0.6400\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9237 - acc: 0.6500\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.8894 - acc: 0.6600\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.9359 - acc: 0.6550\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.8818 - acc: 0.6560\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.9126 - acc: 0.6570\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.9608 - acc: 0.6540\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.9088 - acc: 0.6530\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9091 - acc: 0.6510\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.9349 - acc: 0.6520\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.8800 - acc: 0.6740\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8900 - acc: 0.6640\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.9339 - acc: 0.6750\n",
      "1000/1000 [==============================] - 0s 49us/sample - loss: 0.8868 - acc: 0.6760\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.8671 - acc: 0.6660\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.8283 - acc: 0.6720\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.8456 - acc: 0.6830\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.8206 - acc: 0.6890\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.7673 - acc: 0.6740\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.9147 - acc: 0.6430\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.8646 - acc: 0.6850\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.7988 - acc: 0.6990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.7745 - acc: 0.7080\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.7819 - acc: 0.6920\n",
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.8144 - acc: 0.6970\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.7774 - acc: 0.7030\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.7334 - acc: 0.7240\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.7362 - acc: 0.7250\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.7479 - acc: 0.7100\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.7960 - acc: 0.6910\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.8175 - acc: 0.7010\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.7378 - acc: 0.7270\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.6613 - acc: 0.7520\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.6842 - acc: 0.7190\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.7124 - acc: 0.7370\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.6373 - acc: 0.7540\n",
      "1000/1000 [==============================] - 0s 47us/sample - loss: 0.7021 - acc: 0.7260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5799 - acc: 0.7760\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.7664 - acc: 0.7120\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.6611 - acc: 0.7610\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.5892 - acc: 0.7720\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.5881 - acc: 0.7640\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.5891 - acc: 0.7630\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.5670 - acc: 0.7560\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.6004 - acc: 0.7700\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.5993 - acc: 0.7640\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.6188 - acc: 0.7600\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.5495 - acc: 0.7960\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.6084 - acc: 0.7690\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.5826 - acc: 0.7830\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.6213 - acc: 0.7580\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.5526 - acc: 0.7840\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.5339 - acc: 0.7980\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.4876 - acc: 0.8090\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.5061 - acc: 0.8050\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.4968 - acc: 0.7910\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.4558 - acc: 0.8110\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.5476 - acc: 0.7850\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.5242 - acc: 0.8020\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.4385 - acc: 0.8220\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.4505 - acc: 0.8090\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.4651 - acc: 0.8260\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.4386 - acc: 0.8120\n",
      "1000/1000 [==============================] - 0s 65us/sample - loss: 0.4032 - acc: 0.8390\n",
      "1000/1000 [==============================] - 0s 63us/sample - loss: 0.4098 - acc: 0.8400\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.4149 - acc: 0.8240\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3831 - acc: 0.8360\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.4398 - acc: 0.8350\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.3927 - acc: 0.8430\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.4242 - acc: 0.8400\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3721 - acc: 0.8520\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.3160 - acc: 0.8600\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3118 - acc: 0.8700\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.3726 - acc: 0.8730\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.4060 - acc: 0.8490\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2992 - acc: 0.8690\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.3110 - acc: 0.8830\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.3392 - acc: 0.8660\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.3144 - acc: 0.8780\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.3595 - acc: 0.8570\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2718 - acc: 0.9010\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2777 - acc: 0.8820\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2517 - acc: 0.8990\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.2650 - acc: 0.8790\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.3050 - acc: 0.8900\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.2048 - acc: 0.9200\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.2593 - acc: 0.8980\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.2450 - acc: 0.9110\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.2477 - acc: 0.9010\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.2204 - acc: 0.9060\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.2448 - acc: 0.9060\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.2295 - acc: 0.9130\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.2293 - acc: 0.9140\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1976 - acc: 0.9190\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.2474 - acc: 0.9000\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.2008 - acc: 0.9210\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.2059 - acc: 0.9260\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2198 - acc: 0.9130\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1834 - acc: 0.9260\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.2191 - acc: 0.9230\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2013 - acc: 0.9160\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.2219 - acc: 0.9220\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1780 - acc: 0.9220\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.1811 - acc: 0.9220\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.2040 - acc: 0.9190\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.1639 - acc: 0.9390\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1667 - acc: 0.9360\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1530 - acc: 0.9380\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1681 - acc: 0.9350\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1352 - acc: 0.9480\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.1530 - acc: 0.9430\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1500 - acc: 0.9450\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1309 - acc: 0.9520\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1632 - acc: 0.9450\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1482 - acc: 0.9390\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.1280 - acc: 0.9500\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.1465 - acc: 0.9500\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.1452 - acc: 0.9420\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1217 - acc: 0.9510\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.1187 - acc: 0.9580\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.1013 - acc: 0.9630\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.1137 - acc: 0.9580\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1171 - acc: 0.9560\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0892 - acc: 0.9640\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0951 - acc: 0.9630\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1112 - acc: 0.9540\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1034 - acc: 0.9570\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1078 - acc: 0.9540\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.1297 - acc: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.1041 - acc: 0.9560\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0912 - acc: 0.9730\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0794 - acc: 0.9680\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0890 - acc: 0.9700\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.1019 - acc: 0.9660\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0837 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0950 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0754 - acc: 0.9730\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0862 - acc: 0.9690\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0868 - acc: 0.9650\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0672 - acc: 0.9790\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0647 - acc: 0.9790\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0787 - acc: 0.9740\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0775 - acc: 0.9760\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0835 - acc: 0.9680\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0813 - acc: 0.9700\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0599 - acc: 0.9800\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0605 - acc: 0.9800\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0624 - acc: 0.9810\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0542 - acc: 0.9800\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0643 - acc: 0.9810\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0593 - acc: 0.9870\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0556 - acc: 0.9790\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0461 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0637 - acc: 0.9770\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0443 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0550 - acc: 0.9780\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0395 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0594 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0660 - acc: 0.9770\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0399 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0381 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0503 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0389 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0367 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0479 - acc: 0.9830\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0490 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0454 - acc: 0.9900\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0494 - acc: 0.9830\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0379 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0394 - acc: 0.9870\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0366 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0433 - acc: 0.9880\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0430 - acc: 0.9840\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0232 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0354 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0390 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0318 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0410 - acc: 0.9860\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0308 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0270 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0372 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0305 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0261 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0240 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0282 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0298 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0232 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0245 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.0336 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0275 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0285 - acc: 0.9910\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0247 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0283 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0257 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0288 - acc: 0.9930\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0251 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0204 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0268 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0207 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0265 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0296 - acc: 0.9890\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0192 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0190 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0216 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0218 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0210 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0232 - acc: 0.9950\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0172 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0214 - acc: 0.9940\n",
      "1000/1000 [==============================] - 0s 43us/sample - loss: 0.0185 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0174 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 42us/sample - loss: 0.0187 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0201 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0172 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 45us/sample - loss: 0.0190 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0213 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0267 - acc: 0.9960\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0201 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0212 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0177 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0188 - acc: 0.9980\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 46us/sample - loss: 0.0197 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0194 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0179 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0209 - acc: 0.9970\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0194 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0181 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0200 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0198 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0204 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0198 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0179 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0202 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0226 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0202 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0207 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0196 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0221 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0231 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0235 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0228 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0236 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0273 - acc: 0.9990\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0242 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0261 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0268 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 41us/sample - loss: 0.0289 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0296 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0310 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0361 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0366 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0395 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 34us/sample - loss: 0.0445 - acc: 0.9980\n",
      "1000/1000 [==============================] - 0s 35us/sample - loss: 0.0461 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0530 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 37us/sample - loss: 0.0543 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.0603 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 38us/sample - loss: 0.0650 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0794 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 40us/sample - loss: 0.0910 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 39us/sample - loss: 0.0977 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 44us/sample - loss: 0.1119 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1335 - acc: 1.0000\n",
      "1000/1000 [==============================] - 0s 36us/sample - loss: 0.1533 - acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "probability = np.linspace(0.,1.,500)\n",
    "acc = np.zeros(len(probability))\n",
    "for i,v in enumerate(probability):\n",
    "    #test data\n",
    "    test_mat,test_v = writing_data(1000,11,v)\n",
    "    #evaluate accuracy\n",
    "    test_loss, test_acc = model.evaluate(test_mat, test_v)\n",
    "    acc[i] = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(probability,acc, 'o')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
